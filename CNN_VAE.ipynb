{"cells":[{"cell_type":"code","source":"!pip3 install pyro-ppl\n!pip3 install numpy\n!pip3 install arviz\n!pip3 install matplotlib\n!pip3 install torch\n!pip3 install torchvision","metadata":{"tags":[],"cell_id":"5a7cc487661d4e73bd2e21c3f7c2931a","source_hash":"901545","execution_start":1674074155755,"execution_millis":18210,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: pyro-ppl in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.8.4)\nRequirement already satisfied: numpy>=1.7 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyro-ppl) (1.24.1)\nRequirement already satisfied: torch>=1.11.0 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyro-ppl) (1.13.1)\nRequirement already satisfied: pyro-api>=0.1.1 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyro-ppl) (0.1.2)\nRequirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyro-ppl) (3.3.0)\nRequirement already satisfied: tqdm>=4.36 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pyro-ppl) (4.64.1)\nRequirement already satisfied: typing-extensions in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch>=1.11.0->pyro-ppl) (4.4.0)\nRequirement already satisfied: colorama in c:\\users\\ohe.fi\\appdata\\roaming\\python\\python310\\site-packages (from tqdm>=4.36->pyro-ppl) (0.4.6)\n"},{"name":"stderr","output_type":"stream","text":"\n[notice] A new release of pip available: 22.2.1 -> 22.3.1\n[notice] To update, run: python.exe -m pip install --upgrade pip\n"},{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: numpy in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.24.1)\n"},{"name":"stderr","output_type":"stream","text":"\n[notice] A new release of pip available: 22.2.1 -> 22.3.1\n[notice] To update, run: python.exe -m pip install --upgrade pip\n"},{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: arviz in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.14.0)\nRequirement already satisfied: netcdf4 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from arviz) (1.6.2)\nRequirement already satisfied: numpy>=1.20.0 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from arviz) (1.24.1)\nRequirement already satisfied: setuptools>=60.0.0 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from arviz) (63.2.0)\nRequirement already satisfied: xarray-einstats>=0.3 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from arviz) (0.4.0)\nRequirement already satisfied: xarray>=0.21.0 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from arviz) (2022.12.0)\nRequirement already satisfied: scipy>=1.8.0 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from arviz) (1.10.0)\nRequirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from arviz) (4.4.0)\nRequirement already satisfied: matplotlib>=3.5 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from arviz) (3.6.3)\nRequirement already satisfied: packaging in c:\\users\\ohe.fi\\appdata\\roaming\\python\\python310\\site-packages (from arviz) (23.0)\nRequirement already satisfied: pandas>=1.4.0 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from arviz) (1.5.2)\nRequirement already satisfied: contourpy>=1.0.1 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.5->arviz) (1.0.7)\nRequirement already satisfied: pyparsing>=2.2.1 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.5->arviz) (3.0.9)\nRequirement already satisfied: cycler>=0.10 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.5->arviz) (0.11.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.5->arviz) (1.4.4)\nRequirement already satisfied: pillow>=6.2.0 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.5->arviz) (9.4.0)\nRequirement already satisfied: python-dateutil>=2.7 in c:\\users\\ohe.fi\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib>=3.5->arviz) (2.8.2)\nRequirement already satisfied: fonttools>=4.22.0 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib>=3.5->arviz) (4.38.0)\nRequirement already satisfied: pytz>=2020.1 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pandas>=1.4.0->arviz) (2022.7.1)\nRequirement already satisfied: cftime in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from netcdf4->arviz) (1.6.2)\nRequirement already satisfied: six>=1.5 in c:\\users\\ohe.fi\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib>=3.5->arviz) (1.16.0)\n"},{"name":"stderr","output_type":"stream","text":"\n[notice] A new release of pip available: 22.2.1 -> 22.3.1\n[notice] To update, run: python.exe -m pip install --upgrade pip\n"},{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: matplotlib in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.6.3)\nRequirement already satisfied: numpy>=1.19 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.24.1)\nRequirement already satisfied: cycler>=0.10 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (0.11.0)\nRequirement already satisfied: packaging>=20.0 in c:\\users\\ohe.fi\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (23.0)\nRequirement already satisfied: fonttools>=4.22.0 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (4.38.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.4.4)\nRequirement already satisfied: contourpy>=1.0.1 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (1.0.7)\nRequirement already satisfied: python-dateutil>=2.7 in c:\\users\\ohe.fi\\appdata\\roaming\\python\\python310\\site-packages (from matplotlib) (2.8.2)\nRequirement already satisfied: pillow>=6.2.0 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (9.4.0)\nRequirement already satisfied: pyparsing>=2.2.1 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: six>=1.5 in c:\\users\\ohe.fi\\appdata\\roaming\\python\\python310\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n"},{"name":"stderr","output_type":"stream","text":"\n[notice] A new release of pip available: 22.2.1 -> 22.3.1\n[notice] To update, run: python.exe -m pip install --upgrade pip\n"},{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: torch in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.13.1)\nRequirement already satisfied: typing-extensions in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torch) (4.4.0)\n"},{"name":"stderr","output_type":"stream","text":"\n[notice] A new release of pip available: 22.2.1 -> 22.3.1\n[notice] To update, run: python.exe -m pip install --upgrade pip\n"},{"name":"stdout","output_type":"stream","text":"Requirement already satisfied: torchvision in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.14.1)\nRequirement already satisfied: torch==1.13.1 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.13.1)\nRequirement already satisfied: numpy in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (1.24.1)\nRequirement already satisfied: typing-extensions in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (4.4.0)\nRequirement already satisfied: requests in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (2.28.2)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from torchvision) (9.4.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (3.0.1)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (1.26.14)\nRequirement already satisfied: idna<4,>=2.5 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (3.4)\nRequirement already satisfied: certifi>=2017.4.17 in c:\\users\\ohe.fi\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests->torchvision) (2022.12.7)\n"},{"name":"stderr","output_type":"stream","text":"\n[notice] A new release of pip available: 22.2.1 -> 22.3.1\n[notice] To update, run: python.exe -m pip install --upgrade pip\n"}],"execution_count":1},{"cell_type":"code","source":"from __future__ import print_function\nimport argparse\nimport torch\nimport torch.utils.data\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nfrom torchvision import datasets, transforms\nfrom torchvision.utils import save_image\n\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nimport pyro\nfrom tqdm import tqdm","metadata":{"cell_id":"fd2d3d3775194c24a59fc8f46256a5dd","source_hash":"ecaa84b5","execution_start":1674074177785,"execution_millis":2800,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[{"name":"stderr","output_type":"stream","text":"c:\\Users\\ohe.fi\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n"}],"execution_count":2},{"cell_type":"markdown","source":"# 1. Train the model on the MNIST dataset, using a 2-dimensional latent space. Plot this latent space in the same way as you did for PPCA, using colors to represent the different digits. Does it separate the classes better than PPCA?","metadata":{"cell_id":"04091061a81f4338b918eed7d3fa69ac","deepnote_cell_type":"markdown"}},{"cell_type":"code","source":"cuda2 = False # torch.cuda.is_available() can be used to check if a gpu is available - I just set it to False\nbatch_size2 = 128\nlog_interval2 = 10\nepochs2 = 10 # 10\n\ntorch.manual_seed(1) # args.seed\n\ndevice = torch.device(\"cuda\" if cuda2 else \"cpu\") # args.cuda\nkwargs = {'num_workers': 1, 'pin_memory': True} if cuda2 else {} # args.cuda\n\n# Get train and test data\ntrain_loader = torch.utils.data.DataLoader(\n    datasets.MNIST('../data', train=True, download=True,\n                   transform=transforms.ToTensor()),\n    batch_size=batch_size2, shuffle=True, **kwargs)\ntest_loader = torch.utils.data.DataLoader(\n    datasets.MNIST('../data', train=False, transform=transforms.ToTensor()),\n    batch_size=batch_size2, shuffle=False, **kwargs)","metadata":{"tags":[],"cell_id":"61350cea496a4c35af6959fe64584820","source_hash":"8644574b","execution_start":1674074183943,"execution_millis":771,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":6},{"cell_type":"code","source":"class VAE_CNN(nn.Module):\n    def __init__(self):\n        super(VAE_CNN, self).__init__()\n\n        self.fc1 = nn.Conv2d(1, 16, kernel_size=5)\n        self.fc1a = nn.Conv2d(16, 32, kernel_size=5)\n        self.fc21 = nn.Linear(32*20*20, 5)\n        self.fc22 = nn.Linear(32*20*20, 5)\n        self.fc3 = nn.Linear(5, 64*20*20)\n        self.fc3a = nn.ConvTranspose2d(64, 32, kernel_size=5)\n        self.fc4 = nn.ConvTranspose2d(32, 1, kernel_size=5)\n\n    def encode(self, x):\n        h1 = F.relu(self.fc1(x))\n        h2 = F.relu(self.fc1a(h1))\n        h2 = h2.view(-1, 32*20*20)\n        return self.fc21(h2), self.fc22(h2)\n\n    def reparameterize(self, mu, logvar):\n        std = torch.exp(0.5*logvar)\n        eps = torch.randn_like(std)\n        return mu + eps*std\n\n    def decode(self, z):\n        h3 = F.relu(self.fc3(z))\n        h3 = h3.view(-1, 64, 20, 20)\n        h4 = F.relu(self.fc3a(h3))\n        return torch.sigmoid(self.fc4(h4))\n\n    def forward(self, x):\n        mu, logvar = self.encode(x)\n        z = self.reparameterize(mu, logvar)\n        return self.decode(z), mu, logvar\n\n\n# Reconstruction + KL divergence losses summed over all elements and batch\ndef loss_function(recon_x, x, mu, logvar):\n    BCE = F.binary_cross_entropy(recon_x, x, reduction='sum')\n    KLD = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n    return BCE + KLD # -ELBO\n\n\ndef train(epoch):\n    model.train() # so that everything has gradients and we can do backprop and so on...\n    train_loss = 0\n    for batch_idx, (data, _) in tqdm(enumerate(train_loader)):\n        data = data.to(device)\n        optimizer.zero_grad() # \"reset\" gradients to 0 for text iteration\n        recon_batch, mu, logvar = model(data)\n        loss = loss_function(recon_batch, data, mu, logvar)\n        loss.backward() # calc gradients\n        train_loss += loss.item()\n        optimizer.step() # backpropagation\n\n    print('====> Epoch: {} Average loss: {:.4f}'.format(\n          epoch, train_loss / len(train_loader.dataset)))\n\n\ndef test(epoch):\n    model.eval()\n    test_loss = 0\n    with torch.no_grad(): # no_grad turns of gradients...\n        for i, (data, _) in enumerate(test_loader):\n            data = data.to(device)\n            recon_batch, mu, logvar = model(data)\n            test_loss += loss_function(recon_batch, data, mu, logvar).item()\n\n    test_loss /= len(test_loader.dataset)\n    print('====> Test set loss: {:.4f}'.format(test_loss))\n\n\nmodel = VAE_CNN().to(device)\noptimizer = optim.Adam(model.parameters(), lr=1e-3)","metadata":{"cell_id":"33f2c6fc2bb64cf49ff776dad3cebc27","source_hash":"1b2a83fa","execution_start":1674078801182,"execution_millis":8,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":39},{"cell_type":"code","source":"for epoch in range(1, epochs2 + 1):\n    train(epoch)\n    test(epoch)\n    with torch.no_grad():\n        sample = torch.randn(64, 5).to(device) # 20 -> 2\n        sample = model.decode(sample).cpu()\n        save_image(sample.view(64, 1, 28, 28),\n                   'cnn_sample_' + str(epoch) + '.png')\n\ntorch.save(model, 'cnn_vae.pt')","metadata":{"tags":[],"cell_id":"5ecbccd342f641498ab19abf40fd9632","source_hash":"fe5b88ef","execution_start":1674074204993,"execution_millis":4362988,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = torch.load('cnn_vae.pt')","metadata":{"tags":[],"cell_id":"ed0842322b3048cc91924cb1fc904be9","source_hash":"fad4096b","execution_start":1674078809651,"execution_millis":5,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":19},{"cell_type":"code","source":"def log_px_z(x, z):\n    x_recon = model.decode(z).view(-1, 1, 28, 28)\n    return -F.binary_cross_entropy(x_recon, x.view(-1, 1, 28, 28), reduction='sum')\n\ndef log_pt(x, parms, beta):\n    log_like = log_px_z(x, parms['z'])\n    log_prior = torch.distributions.MultivariateNormal(torch.zeros(5), torch.eye(5)).log_prob(parms['z'])\n\n    return beta * log_like + log_prior\n\ndef log_pt_encoder(x, parms, beta):\n    log_like = log_px_z(x, parms['z'])\n    log_prior = torch.distributions.MultivariateNormal(torch.zeros(5), torch.eye(5)).log_prob(parms['z'])\n    mu, logvar = model.encode(x)\n    log_enc = torch.distributions.MultivariateNormal(mu, torch.eye(5)*torch.exp(0.5*logvar)).log_prob(parms['z'])\n    return beta * (log_like + log_prior ) + (1 - beta) * log_enc\n\ndef log_IS_frac(x, z, m, s):\n    q_z_x = torch.distributions.MultivariateNormal(m, torch.eye(5)*torch.exp(0.5*s)).log_prob(z)\n    return log_pt(x, {'z': z}, 1) - q_z_x\n    ","metadata":{"tags":[],"cell_id":"8ad47b8d1dc84c809965e82f51d78154","source_hash":"29960793","execution_start":1674079247184,"execution_millis":0,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":43},{"cell_type":"code","source":"def AIS_encoder(x, N, T):\n    betas = np.linspace(0, 1, T)\n    \n    beta_diff = 1.0 / T\n    chain_log_like = torch.zeros(N, dtype=torch.float64)\n    mu, logvar = model.encode(x)\n    for t in range(T-1):\n        nuts = pyro.infer.NUTS(potential_fn=lambda parms: -log_pt_encoder(x, parms, betas[t]))\n        \n        mcmc = pyro.infer.MCMC(nuts, num_samples=N, warmup_steps=10, initial_params={'z': torch.randn(1, 5)}, disable_progbar=True)\n        mcmc.run()\n\n        z = mcmc.get_samples()['z']\n        for n in range(N):\n            log_prior = torch.distributions.MultivariateNormal(torch.zeros(5), torch.eye(5)).log_prob(z[n])[0]\n            log_enc = torch.distributions.MultivariateNormal(mu, torch.eye(5)*torch.exp(0.5*logvar)).log_prob(z[n])[0]\n            chain_log_like[n] += beta_diff * (log_px_z(x, z[n]) + log_prior - log_enc)\n\n    if N == 1:\n        return chain_log_like[0]\n    \n    chain_like = torch.exp(chain_log_like)\n    return torch.log(torch.mean(chain_like))\n\ndef IS_encoder(x, N):\n    log_fracs = torch.zeros(N, dtype=torch.float64)\n    m, s = model.encode(x)\n    for n in range(N):\n        z = model.reparameterize(m, s)\n        log_fracs[n] = log_IS_frac(x, z, m, s)\n    \n    return torch.log(torch.exp(log_fracs).mean())","metadata":{"tags":[],"cell_id":"db75879dbc5e474fada66710b9172782","source_hash":"6060dcf8","execution_start":1674079662497,"execution_millis":2,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":41},{"cell_type":"code","source":"data = list(test_loader)\nn_test_batch = 4\n\nnlls = np.zeros(batch_size2 * n_test_batch)\nfor i in range(n_test_batch):\n    x = data[i][0]\n    for j in tqdm(range(batch_size2)):\n        nlls[i*batch_size2+j] = -AIS_encoder(x[j], 1, 100)\n    print(np.mean(nlls[:batch_size2*(i+1)]))","metadata":{"tags":[],"cell_id":"37545b032e5c4e66bfcf2ae0c8f09491","source_hash":"f7750d51","execution_start":1674079667595,"execution_millis":2760956,"deepnote_to_be_reexecuted":false,"deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"code","source":"data = list(test_loader)\nn_test_batch = 50\n\nnlls = np.zeros(batch_size2 * n_test_batch)\nfor i in range(n_test_batch):\n    x = data[i][0]\n    for j in tqdm(range(batch_size2)):\n        nlls[i*batch_size2+j] = -IS_encoder(x[j], 1000)\n    print(np.mean(nlls[:batch_size2*(i+1)]))","metadata":{"cell_id":"ec04147d1c8e466a8050b05984fe25ad","deepnote_cell_type":"code"},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=f2080f7a-92d1-4485-9403-98db2db3ab51' target=\"_blank\">\n<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>\nCreated in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>","metadata":{"tags":[],"created_in_deepnote_cell":true,"deepnote_cell_type":"markdown"}}],"nbformat":4,"nbformat_minor":0,"metadata":{"vscode":{"interpreter":{"hash":"ac7b47472e5c453ec29fc79f0513f4270e08b2f36f8483bab0a6ba15b9534a4a"}},"deepnote":{},"kernelspec":{"name":"python3","language":"python","display_name":"Python 3.10.6 64-bit"},"language_info":{"name":"python","version":"3.10.6","mimetype":"text/x-python","file_extension":".py","pygments_lexer":"ipython3","codemirror_mode":{"name":"ipython","version":3},"nbconvert_exporter":"python"},"deepnote_notebook_id":"c14e2c55703a4671b2706215c2155c0e","deepnote_execution_queue":[]}}